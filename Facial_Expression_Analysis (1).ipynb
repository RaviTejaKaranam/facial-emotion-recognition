{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('C:/Users/MVRAHUL/Downloads/fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\ipykernel_launcher.py:16: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#declaring variables\n",
    "width, height = 48, 48\n",
    "\n",
    "datapoints = dataset['pixels'].tolist()\n",
    "\n",
    "#getting features for training\n",
    "X = []\n",
    "for xseq in datapoints:\n",
    "    xx = [int(xp) for xp in xseq.split(' ')]\n",
    "    xx = np.asarray(xx).reshape(width, height)\n",
    "    X.append(xx.astype('float32'))\n",
    "\n",
    "X = np.asarray(X)\n",
    "X = np.expand_dims(X, -1)\n",
    "\n",
    "#getting labels for training\n",
    "y = pd.get_dummies(dataset['emotion']).as_matrix()\n",
    "\n",
    "X -= np.mean(X, axis=0)\n",
    "X /= np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "num_features = 32\n",
    "num_labels = 7\n",
    "batch_size = 64\n",
    "epochs = 25\n",
    "width, height = 48, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(48, 48, 1...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "#adding layers\n",
    "classifier.add(Convolution2D( num_features,3,3 , activation='relu', input_shape=(width, height, 1)))#, data_format='channels_last', kernel_regularizer=l2(0.01)))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\n",
    "classifier.add(Convolution2D( num_features*2,3,3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "               \n",
    "classifier.add(Flatten())\n",
    "\n",
    "\n",
    "classifier.add(Dense(2*num_features, activation='relu'))\n",
    "classifier.add(Dense(num_labels, activation='softmax'))\n",
    "\n",
    "# Compiling the CNNadam\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Epoch 1/25\n",
      "28709/28709 [==============================] - 82s 3ms/step - loss: 0.3379 - acc: 0.8687\n",
      "Epoch 2/25\n",
      "28709/28709 [==============================] - 77s 3ms/step - loss: 0.2924 - acc: 0.8833\n",
      "Epoch 3/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.2683 - acc: 0.8917: 0s - loss: 0.2684 - acc: 0.89\n",
      "Epoch 4/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.2466 - acc: 0.9001: 4s \n",
      "Epoch 5/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.2242 - acc: 0.9093\n",
      "Epoch 6/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.2007 - acc: 0.9192\n",
      "Epoch 7/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.1765 - acc: 0.9302\n",
      "Epoch 8/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.1535 - acc: 0.9395\n",
      "Epoch 9/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.1299 - acc: 0.9508: 1s - loss: 0.1295 - a\n",
      "Epoch 10/25\n",
      "28709/28709 [==============================] - 81s 3ms/step - loss: 0.1095 - acc: 0.9593\n",
      "Epoch 11/25\n",
      "28709/28709 [==============================] - 87s 3ms/step - loss: 0.0901 - acc: 0.9663\n",
      "Epoch 12/25\n",
      "28709/28709 [==============================] - 87s 3ms/step - loss: 0.0731 - acc: 0.9739\n",
      "Epoch 13/25\n",
      "28709/28709 [==============================] - 80s 3ms/step - loss: 0.0592 - acc: 0.9792\n",
      "Epoch 14/25\n",
      "28709/28709 [==============================] - 79s 3ms/step - loss: 0.0507 - acc: 0.9827\n",
      "Epoch 15/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.0424 - acc: 0.9858\n",
      "Epoch 16/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.0374 - acc: 0.9876\n",
      "Epoch 17/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.0319 - acc: 0.9895\n",
      "Epoch 18/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.0281 - acc: 0.9909\n",
      "Epoch 19/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.0273 - acc: 0.9911\n",
      "Epoch 20/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.0261 - acc: 0.9914A: 4s - \n",
      "Epoch 21/25\n",
      "28709/28709 [==============================] - 79s 3ms/step - loss: 0.0218 - acc: 0.9932: 1s - loss: 0.0216 - ac\n",
      "Epoch 22/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.0188 - acc: 0.9943: 4s - \n",
      "Epoch 23/25\n",
      "28709/28709 [==============================] - 78s 3ms/step - loss: 0.0215 - acc: 0.9931\n",
      "Epoch 24/25\n",
      "28709/28709 [==============================] - 80s 3ms/step - loss: 0.0208 - acc: 0.9935\n",
      "Epoch 25/25\n",
      "28709/28709 [==============================] - 81s 3ms/step - loss: 0.0201 - acc: 0.9935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24fd1aac0c8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting model to the Training set\n",
    "classifier.fit(np.array(X_train), np.array(y_train),\n",
    "          batch_size = batch_size,\n",
    "          nb_epoch = epochs)\n",
    "        #,validation_data=(np.array(X_valid), np.array(y_valid)),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#saving trained model\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "#saving the  model to be used later\n",
    "fer_json = classifier.to_json()\n",
    "with open(\"xyz_2.json\", \"w\") as json_file:\n",
    "    json_file.write(fer_json)\n",
    "classifier.save_weights(\"fer_2.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #saving the  model to be used later\n",
    "# fer_json = model.to_json()\n",
    "# with open(\"xyz.json\", \"w\") as json_file:\n",
    "#     json_file.write(fer_json)\n",
    "# classifier.save_weights(\"fer.h5\")\n",
    "# print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\MVRAHUL\\Anaconda3\\envs\\envi\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('xyz_2.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"fer_2.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 1. 0.]]\n",
      "Emotion: Surprise\n"
     ]
    }
   ],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.models import model_from_json\n",
    "\n",
    "# from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import numpy\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#setting image resizing parameters\n",
    "WIDTH = 48\n",
    "HEIGHT = 48\n",
    "x=None\n",
    "y=None\n",
    "labels = ['Angry', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\n",
    "\n",
    "#loading image\n",
    "full_size_image = cv2.imread(\"sur.jpg\")\n",
    "gray=cv2.cvtColor(full_size_image,cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "face = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "faces = face.detectMultiScale(gray, 1.3  , 10)\n",
    "# print(faces)\n",
    "#detecting faces\n",
    "for (x, y, w, h) in faces:\n",
    "    roi_gray = gray[y:y + h, x:x + w]\n",
    "    cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray, (48, 48)), -1), 0)\n",
    "    cv2.normalize(cropped_img, cropped_img, alpha=0, beta=1, norm_type=cv2.NORM_L2, dtype=cv2.CV_32F)\n",
    "    cv2.rectangle(full_size_image, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "        \n",
    "    #predicting the emotion\n",
    "    yhat= loaded_model.predict(cropped_img)\n",
    "    print(yhat)\n",
    "    cv2.putText(full_size_image, labels[int(np.argmax(yhat))], (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 1, cv2.LINE_AA)\n",
    "    print(\"Emotion: \"+labels[int(np.argmax(yhat))])\n",
    "\n",
    "    \n",
    "\n",
    "cv2.imshow('Emotion', full_size_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
